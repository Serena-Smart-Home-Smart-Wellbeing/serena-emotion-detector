{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87412da1-e7a1-4571-ad81-3402ce838a96",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc78e4ff-c0c6-4bf7-a694-d7a255d9968c",
   "metadata": {},
   "source": [
    "Run this `gcsfuse` cell if you can't list the folders inside of \"/gcs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2835b124-cf4b-4cfa-abeb-94afb1325bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I1109 09:30:46.322746 2023/11/09 09:30:46.322720 Start gcsfuse/0.42.5 (Go version go1.20.3) for app \"\" using mount point: /home/jupyter/gcs\n",
      "daemonize.Run: readFromProcess: sub-process: mountWithArgs: mountWithConn: Mount: mount: running /usr/bin/fusermount: exit status 1\n"
     ]
    }
   ],
   "source": [
    "!gcsfuse --implicit-dirs \"~/gcs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0d803a-800b-4034-a20b-4aedfcae36ab",
   "metadata": {},
   "source": [
    "When using GCS buckets, use \"/gcs\" instead of \"gs://\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4072b321-d2fc-4fdf-9a29-636d0db1fdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset_path = \"/home/jupyter/gcs/serena-shsw-datasets\"\n",
    "training_dataset = dataset_path + \"/FER-2013/train\"\n",
    "test_dataset = dataset_path + \"/FER-2013/test\"\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "#training_dataset, validation_dataset = train_test_split(training_dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Output directory contents\n",
    "!echo \"Train\"\n",
    "!ls {training_dataset}\n",
    "!echo \"Test\"\n",
    "!ls {test_dataset}\n",
    "!echo \"Valid\"\n",
    "!ls{validation_dataset}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e551140-4b61-4fe3-9177-f00fb2ee4d0e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6aecf3bc-df57-4f51-84c6-b17bfc65dc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 09:30:59.153559: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-09 09:30:59.306203: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-11-09 09:30:59.306234: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-11-09 09:31:00.130875: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-11-09 09:31:00.130988: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-11-09 09:31:00.130999: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import string\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df549b7f-ef2b-4968-8b7d-57a0cfc87bd2",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7faaf57-8fc2-4308-a022-1275e4424646",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4f72f5-8088-456b-876b-e2e6defb3674",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7  # Gantikan dengan jumlah sebenarnya dari kelas emosi dalam dataset Anda\n",
    "batch_size = 32 * 4 # 128 seems to be ideal\n",
    "num_epochs = 10\n",
    "train_data_dir = 'path_to_train_data_directory'\n",
    "validation_data_dir = 'path_to_validation_data_directory'\n",
    "test_data_dir = 'path_to_test_data_directory'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f854c94-0cd7-425c-8fde-8f43c2d60640",
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_classes = 7  # Gantikan dengan jumlah sebenarnya dari kelas emosi dalam dataset Anda\n",
    "\n",
    "#x = layers.GlobalAveragePooling2D()(x)\n",
    "#x = layers.Dense(1024, activation='relu')(x)\n",
    "#predictions = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "#model = models.Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac31957-9e83-4578-a10f-8c9b85cb8ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(7, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b62b5df-9985-40db-88d5-3eff206ca74e",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118d8cec-1663-4a2a-8f01-cfaeef0ba351",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=training_dataset,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82ee651-8c1b-4a3a-a383-0fe98ec8bbbc",
   "metadata": {},
   "source": [
    "# Data Generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b28679-f4d5-4d3b-9536-1effdba2d8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    directory=test_dataset,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b8911a-587c-4299-b4af-280c1b3ffef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d346d65c-68f5-4f79-9d07-a9cc8ac577b0",
   "metadata": {},
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10, \n",
    "    validation_data=validation_generator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94860c7d-70e5-4f86-9eaa-b6e8c4cd4fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03469a69-c672-46e7-9a41-22dac61b7718",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fea33e0c-5e78-4d3a-8478-f25664315a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_path = dataset_path + \"/models/serena-emotion-detector.keras\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c76b300-4c71-4a1a-94f7-5330e61f8909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use new .keras format for easier usage & better debugging\n",
    "model.save(saved_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467837ab-e2f6-4cb8-a237-f433a92d58dc",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "707d6e6e-e237-4bc4-b292-626fb837c0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 512)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 1799      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,847,815\n",
      "Trainable params: 133,127\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "saved_emotion_detector = tf.keras.models.load_model(saved_model_path)\n",
    "\n",
    "# Check its architecture\n",
    "saved_emotion_detector.summary()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-11:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
