{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97797b7-eaa5-4b81-bfce-103ed7955af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# This notebook is only for developing, training, and saving the model. For evaluating the model, check `evaluate.ipynb`.\n",
    "\n",
    "# # Datasets\n",
    "\n",
    "# Run this `gcsfuse` cell if you can't list the folders inside of \"/gcs\"\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# When using GCS buckets, use \"/gcs\" instead of \"gs://\"\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "!gcsfuse --implicit-dirs \"~/gcs\"\n",
    "dataset_path = \"/gcs/serena-shsw-datasets\"\n",
    "training_dataset = dataset_path + \"/FER-SERENA/train/train\"\n",
    "test_dataset = dataset_path + \"/FER-SERENA/test/test\"\n",
    "validation_dataset = dataset_path + \"/FER-SERENA/valid/validation\"\n",
    "\n",
    "# Output directory contents\n",
    "\n",
    "\n",
    "# # Import Library\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Input  # Import Input layer\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# # PRE-PROCESSING DATA\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "# Define ImageDataGenerator for data augmentation and loading\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "img_size = (48, 48)\n",
    "batch_size = 64\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    training_dataset,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dataset,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dataset,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "# # Create Model\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', kernel_initializer='he_normal', input_shape=(48, 48, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, kernel_initializer='he_normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(64, kernel_initializer='he_normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(7, kernel_initializer='he_normal'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# # Data Generating\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "# Compile your model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=200,\n",
    ")\n",
    "\n",
    "\n",
    "# # Saving Model\n",
    "\n",
    "# Vertex AI expects the model artifacts to be saved in `BASE_OUTPUT_DIRECTORY/model/` when you want to train a new version of a model\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "saved_model_path = dataset_path + \"/models/serena-emotion-detector/model\"\n",
    "\n",
    "# Do not uncomment this line, it will be done by setup.sh\n",
    "model.save(saved_model_path)\n",
    "\n",
    "\n",
    "# After saving, use `evaluate.ipynb` to evaluate the model after loading the artifacts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefbf7a4-2d38-4671-92a4-567d00e6f103",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61835da1-1eaf-485b-b919-2fe4edd75e57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-11:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
